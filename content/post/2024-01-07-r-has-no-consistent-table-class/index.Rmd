---
title: "R has no consistent table class"
author: ~
date: '2024-01-08'
slug: []
categories: []
tags:
- Programming
- R
- Python
- Rust
- Relational model
- autodb
- Data structures
subtitle: "And neither do Python and Rust"
summary: ''
authors: []
lastmod: '2024-03-25'
featured: no
draft: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
math: true
---

## The usual case

R, in addition to being array-based, can also be table-based: it has a table class in the base language, `data.frame`. This is great, because a lot of data comes in table form.

Here are some simple examples:

```{r}
twocols <- data.frame(
  a = rep(1:3, 4),
  b = rep(1:2, 6)
)
twocols
onecol <- data.frame(
  a = rep(1, 5)
)
onecol
```

One thing we can do with these tables is to look for, or remove, duplicate rows:

```{r}
duplicated(twocols)
duplicated(onecol)
unique(twocols)
unique(onecol)
```

Simple enough, right? Right.

## The edge case

Now let's try this with a data frame with no columns. This is something that R allows, so this should work as expected.

```{r}
nocol <- onecol[, FALSE, drop = FALSE]
nocol
```

Now, what do we expect to happen when we look for duplicates? Well, every row is the same, so every row after the first is a duplicate, so `unique` should leave a single row. The fact that the rows contain no data is irrelevant. What actually happens?

```{r}
duplicated(nocol)
```

`duplicated` returns a zero-length vector, as if there were no rows. This results in R claiming there are no rows after removing duplicates:

```{r}
unique(nocol)
```

Uh oh. How about if we only have the one row to begin with?

```{r}
nocol_onerow <- nocol[1, , drop = FALSE]
nocol_onerow
duplicated(nocol_onerow)
unique(nocol_onerow)
```

Oh, dear.

## Why this matters

In practice, a table with no columns is not going to turn up much, so you could argue that this doesn't matter. However, it should matter, if nothing else, for reasons of consistency: if we're working programmatically, we have no idea what dimension of table we're working with.

In fact, I've run into this problem multiple times when writing the `autodb` package for decomposing a data table into a partially-normalised database.

A database is composed of several relations, which are tables with some additional information. One piece of additional information is the relation's (candidate) keys, which are sets of the columns that, together, uniquely determine the rows. Each row has a unique set of values for the key's columns; vice versa, knowing the values for the key's columns determines which row we're looking at.

When turning a table of real data into a database, you can get a relation with an empty key. This happens when a column has the same value in every row: its value is constant, and determinable with no information. Such a relation can only have 0 or 1 rows, since an empty key can't distinguish between multiple rows.

There are a few reasons an empty key is a problem in R, given how we saw its data frames deal with this case, but let's take the example where we're checking that a given database is valid. One thing we need to check is that the columns in each key of a relation have unique values over its rows.

For example, suppose `x` above has both of its columns as its sole key. Does the key have unique values over its rows? No, because there are duplicates:

```{r}
twocols_key <- c("a", "b")
anyDuplicated((twocols[, twocols_key, drop = FALSE])) # returns 0 if unique
```

However, removing the duplicates makes the key values unique:

```{r}
anyDuplicated(unique(twocols)[, twocols_key, drop = FALSE])
```

Now, let's try validating a valid table with an empty key, which can only have 0 or 1 rows:

```{r}
v <- data.frame(a = 1L, b = 2L, c = FALSE)
v
v_key <- character()
anyDuplicated(v[, v_key, drop = FALSE]) # the right answer...
duplicated(v[, v_key, drop = FALSE]) # ... for the wrong reason
```

How about if that table invalidly has multiple rows?

```{r}
u <- data.frame(a = c(1L, 2L), b = c(2L, 3L), c = c(FALSE, TRUE))
u
u_key <- character()
anyDuplicated(u[, u_key, drop = FALSE]) # the wrong answer...
duplicated(u[, u_key, drop = FALSE]) # ... for the wrong reason
```

This shows that we can run into this problem, even when dealing with realistic data.
This is clearly a problem when writing a library that models databases! I end up having to write nasty code like this:

```{r}
dups <- if (length(u_key) == 0) {
  if (nrow(u) == 0)
    logical() # length 0 boolean vector
  else
    c(FALSE, rep(TRUE, nrow(u) - 1))
}else
  duplicated(u[, u_key, drop = FALSE])
dups
u[dups, , drop = FALSE]
```

## Tibbles are inconsistent

OK, R's base `data.frame` class is inconsistent, but people also like to use the `tibble` and `data.table` classes instead, from their eponymous libraries. Do they do any better?

Here's `tibble`:

```{r}
library(tibble)
nocol_tib <- as_tibble(nocol) # should be 5x0
nocol_tib
nocol_onerow_tib <- as_tibble(nocol_onerow) # should be 1x0
nocol_onerow_tib
```

The row counts are preserved, as before.

```{r}
duplicated(nocol_tib)
try(unique(nocol_tib))
duplicated(nocol_onerow_tib)
try(unique(nocol_onerow_tib))
```

Asking for unique rows, however, returns an error. That's no good, although it's probably better than the base data frames silently doing the wrong thing.

## Data tables are inconsistent

How about `data.table`?

```{r}
library(data.table)
nocol_dt <- as.data.table(nocol) # should be 5x0
nocol_dt
nocol_onerow_dt <- as.data.table(nocol_onerow) # should be 1x0
nocol_onerow_dt
```

As much as I like `data.table` over `tibble`, this is even worse: the rows are all dropped on conversion. Creating the table directly as a `data.table`, instead of converting from a `data.frame`, makes no difference.

## Arrow tables are inconsistent

Another table class is `arrow`, which is an interface for Apache's Arrow C++ library. How does `arrow` do?

```{r}
library(arrow)
nocol_arw <- as_arrow_table(nocol)
nocol_arw
nocol_onerow_arw <- as_arrow_table(nocol_onerow)
nocol_onerow_arw
```

Not well: all rows are dropped, as they were for `data.table`.

```{r}
try(duplicated(nocol_arw))
unique(nocol_arw)
try(duplicated(nocol_onerow_arw))
unique(nocol_onerow_arw)
```

Furthermore, `duplicated`, can't be used at all, because there's no `duplicated` method for Arrow tables, only one for `unique`.

## Files and file-driven table classes aren't consistent either

We've looked at table classes within an R session. How do file formats do for read/write operations handling zero columns properly?

We look at four formats here[^0]:

[^0]: We don't consider `data.table`'s `fread` and `fwrite` here, since we know that the `data.table` format can't handle zero columns anyway.

- `csv`, handled with basic R read/write functions, and the `parquetize` and `vroom` packages;
- `feather`, handled with the `feather` and `arrow` packages;
- `fst`, handled with the `fst` package;
- `parquet`, handled with the `parquetize` and `arrow` packages.

Since `parquet` should be able to read from several file formats, we check this one as we go.[^1]

[^1]: Feather and Parquet files can also be read with the `arrow` package, with the same result, since both are integrated with Apache Arrow.

The basic issue is that writing a zero-column data frame to a CSV file results in something that can't be parsed properly:

```{r}
tf <- tempfile()
write.csv(nocol, tf, row.names = FALSE)
readLines(tf)
try(read.csv(tf, row.names = FALSE))
```

`parquet` and `vroom` don't have much better luck writing and reading it:

```{r}
tf_parquet <- tempfile() # for writing parquet files via parquetize
tf_parquet_arrow <- tempfile() # for writing parquet files via arrow
try(parquetize::csv_to_parquet(tf, path_to_parquet = tf_parquet))
vroom::vroom(tf, delim = ",")
```

I wasn't expecting any option to turn a $5 \times 0$ table into a $0 \times 1$ table, but there it is.

Writing the row names doesn't improve matters much:

```{r}
tf_rn <- tempfile()
write.csv(nocol, tf_rn, row.names = TRUE)
readLines(tf_rn)
try(read.csv(tf_rn, row.names = TRUE))
try(parquetize::csv_to_parquet(tf_rn, path_to_parquet = tf_parquet))
vroom_tf_rn <- vroom::vroom(tf_rn, delim = ",")
subset(vroom::problems(vroom_tf_rn), , -file)
vroom_tf_rn
```

`vroom` now returns a $5 \times 1$ table, where the row names are misread as the single column's values.

How about `feather`?

```{r}
tf_feather <- tempfile()
tf_feather_arrow <- tempfile()
feather::write_feather(nocol, tf_feather)
feather::read_feather(tf_feather)
arrow::write_feather(nocol, tf_feather_arrow)
arrow::read_feather(tf_feather_arrow)
try(feather::read_feather(tf_feather_arrow))
arrow::read_feather(tf_feather)
```

We have slightly better luck here, depending on which package we use to handle Feather files.

We're not so lucky with `fst`:

```{r}
tf_fst <- tempfile()
fst::write_fst(nocol, tf_fst)
fst::read_fst(tf_fst)
arrow::write_parquet(nocol, tf_parquet_arrow)
arrow::read_parquet(tf_parquet_arrow)
```

Let's summarise everything done above for the $5 \times 0$ table `nocol`:

```{r, echo=FALSE, results='hide'}
dim_summary <- data.frame(
  format = c(
    "vroom w/o rownames",
    "vroom w/ rownames",
    "feather (write feather, read feather)",
    "feather (write arrow, read arrow)",
    "feather (write feather, read arrow)",
    "fst",
    "parquet"
  ),
  rows = vapply(
    list(
      vroom::vroom(tf, delim = ",", show_col_types = FALSE, .name_repair = "unique_quiet"),
      vroom::vroom(tf_rn, delim = ",", show_col_types = FALSE, .name_repair = "unique_quiet"),
      feather::read_feather(tf_feather),
      arrow::read_feather(tf_feather_arrow),
      arrow::read_feather(tf_feather),
      fst::read_fst(tf_fst),
      arrow::read_parquet(tf_parquet_arrow)
    ),
    nrow,
    integer(1)
  ),
  cols = vapply(
    list(
      vroom::vroom(tf, delim = ",", show_col_types = FALSE, .name_repair = "unique_quiet"),
      vroom::vroom(tf_rn, delim = ",", show_col_types = FALSE, .name_repair = "unique_quiet"),
      feather::read_feather(tf_feather),
      arrow::read_feather(tf_feather_arrow),
      arrow::read_feather(tf_feather),
      fst::read_fst(tf_fst),
      arrow::read_parquet(tf_parquet_arrow)
    ),
    ncol,
    integer(1)
  )
)
```

```{r, echo=FALSE}
knitr::kable(dim_summary)
```

The only library that gives the correct dimensions here is `feather` as the file writer. However, it's only correct when writing the file using the original `feather` package: that package hasn't been updated since 2019, since the format was integrated into Apache Arrow and it was integrated into `arrow`, so there are no maintained packages that get this right.

## Pandas is no better

Come on, we can't make it look like Python is preferable.

```{python}
import pandas as pd
```

A 2x1 table works as expected:

```{python}
py_onecol = pd.DataFrame(data = {'a': [1, 1]})
py_onecol
py_onecol.duplicated()
py_onecol.drop_duplicates()
```

But now let's remove the only column:

```{python}
py_nocol = py_onecol.iloc[[0, 1], []]
py_nocol
py_nocol.duplicated()
py_nocol.drop_duplicates()
```

Like `data.table`, this treats the table as empty.

`duplicated` and `drop_duplicates` take a subset of columns to check, so we could use this for uniqueness checks by taking the subset as our key. What if the table has a non-zero number of columns, but the key is empty?

```{python}
py_onecol2 = pd.DataFrame(data = {'a': [1, 2]})
py_onecol2
try: py_onecol2.duplicated(subset = [])
except Exception as e: print(e)
try: py_onecol2.drop_duplicates(subset = [])
except Exception as e: print(e)
```

Well, that's no good either.

## Rust's polars is no better

[As it turns out](https://github.com/pola-rs/r-polars), we can call Rust's polars library for data frames from R:

```{r}
library(polars)
ps <- pl$DataFrame(a = 1:5)
ps
rownames(ps)
ps$select()
rownames(ps$select())
```

This is the same behaviour as that of `data.table` -- not surprising, since polars is inspired by pandas -- so even the Rustaceans don't get this right.

## Why it's like this, and possible fixes

I can't say for the other implementations, but let's look at base R's code for `duplicated.data.frame`:

```{r}
duplicated.data.frame
```

Here we see an approach for looking for duplicate columns that I've used directly before: use `Map(list, x)`, after some tidying of `x`, to return a list of rows, where each row is given as the list of its values. Effectively, we take the column-based data frame format, and turn it inside out to get a row-based format. We then check whether these rows are duplicated, using `duplicated`'s default method, so we're comparing list elements instead of several columns at once.

This is a reasonable approach if we have at least one column. What happens if we try this conversion with no columns?

Data frames are stored as a list, with each element giving a column's values, and the elements having to be the same length. If there are no columns, this list is empty:

```{r}
unclass(nocol)
```

Therefore, `Map(list, z)` returns an empty list, rather than a list of empty row lists:

```{r}
Map(list, nocol)
```

When we pass this into `duplicated`, of course, we get a zero-length logical vector.

I don't think there's much that can be done about this, outside of changing how data frames are stored. It's a strange situation where only the row names preserve the row count. If we make a copy where they're removed, as done in `data.table`, then this information is lost:

```{r}
a <- nocol
attr(a, "row.names") <- NULL # skips `row.names<-` sanity checks
a
unclass(a)
```

In turn, this information is only kept because, when asked for a data frame's row count, R uses the row names:

```{r}
nrow
dim.data.frame
```

Effectively, the row names are used like a "header", but for the rows instead of the columns. This is probably why, if you try to remove them with something like `row.names(a) <- NULL`, R immediately adds integer row names as replacements: removing row names completely would break the information about the table's size, in a way that removing the column names can't. We can see this with tables that have columns, too:

```{r}
b <- data.frame(a = 1:4, b = 2:3)
dim(b)
attr(b, "row.names") <- NULL # attr lets us treat classes as mere suggestions
dim(b) # R now thinks there are 0 rows...
unclass(b) # ... but the data's still there
length(b$a)
```

This means that we could fix `duplicated.data.frame` by having it make use of the row names. What would such an implementation of `duplicated` for tables look like? Writing it in a way that's agnostic to the number of columns is easy enough, but might be inefficient:

```{r}
duplicated2 <- function(x, incomparables = FALSE, fromLast = FALSE, ...) {
  UseMethod("duplicated2")
}
duplicated2.data.frame <- function(x, incomparables = FALSE, fromLast = FALSE, ...) {
  if (!isFALSE(incomparables)) 
    .NotYetUsed("incomparables != FALSE")
  if (any(i <- vapply(x, is.factor, NA))) 
    x[i] <- lapply(x[i], as.numeric)
  lst <- lapply(
    seq_along(row.names(x)),
    function(row) `rownames<-`(`names<-`(x[row, , drop = TRUE], NULL), NULL)
  )
  duplicated(lst, fromLast = fromLast, ...)
}
duplicated2(nocol)
duplicated2(nocol_onerow)
duplicated2(twocols)
duplicated2(onecol)
```

Maybe it's just better to add a second explicit edge case, so we're not relying on `nrow` using the row names:

```{r}
duplicated3 <- function(x, incomparables = FALSE, fromLast = FALSE, ...) {
  UseMethod("duplicated3")
}
duplicated3.data.frame <- function(x, incomparables = FALSE, fromLast = FALSE, ...) {
    if (!isFALSE(incomparables)) 
        .NotYetUsed("incomparables != FALSE")
    if (length(x) == 0L) {
      nr <- nrow(x)
      if (nr == 0L)
        return(logical())
      else
        return(c(FALSE, rep_len(TRUE, nr - 1L)))
    }
    if (length(x) != 1L) {
        if (any(i <- vapply(x, is.factor, NA))) 
            x[i] <- lapply(x[i], as.numeric)
        duplicated(do.call(Map, `names<-`(c(list, x), NULL)), 
            fromLast = fromLast)
    }
    else duplicated(x[[1L]], fromLast = fromLast, ...)}
duplicated3(nocol)
duplicated3(nocol_onerow)
duplicated3(twocols)
duplicated3(onecol)
```

It looks like it would also be quicker, at least for small tables like these:

```{r}
microbenchmark::microbenchmark(
  duplicated2(nocol),
  duplicated3(nocol),
  times = 1000,
  check = "identical"
)
microbenchmark::microbenchmark(
  duplicated2(nocol_onerow),
  duplicated3(nocol_onerow),
  times = 1000,
  check = "identical"
)
microbenchmark::microbenchmark(
  duplicated(twocols),
  duplicated2(twocols),
  duplicated3(twocols),
  times = 1000,
  check = "identical"
)
microbenchmark::microbenchmark(
  duplicated(onecol),
  duplicated2(onecol),
  duplicated3(onecol),
  times = 1000,
  check = "identical"
)
```

For `autodb` classes, I'll probably be writing something like `duplicated3` for internal use, so I don't have this edge case all over the code any more.

## Environment used

R session information:

```{r}
sessionInfo()
```

Python version (a little old, but installing/updating things in Python is so awful I don't want to do it again):

```{python}
import sys
print(sys.version)
```
