---
title: "Codex model"
output:
  html_document:
    number_sections: false
    self_contained: yes
    code_folding: none
    df_print: paged
author: "Mark Webster"
date: 2020-02-16
---

<script src="/rmarkdown-libs/htmlwidgets/htmlwidgets.js"></script>
<script src="/rmarkdown-libs/pymjs/pym.v1.js"></script>
<script src="/rmarkdown-libs/widgetframe-binding/widgetframe.js"></script>


<div id="simulation-configuration" class="section level1">
<h1>Simulation configuration</h1>
<p>Current model sample size is 4000. However, since we use a Markov Chain sampler, the samples are correlated: the effective sample size varies between different parameters, within the range (1036, 8652).</p>
</div>
<div id="posterior-model-performance" class="section level1">
<h1>Posterior model performance</h1>
<div id="htmlwidget-1" style="width:100%;height:100%;" class="widgetframe html-widget"></div>
<script type="application/json" data-for="htmlwidget-1">{"x":{"url":"/codex_model_files/figure-html//widgets/widget_Matchup predictions for mean performance models.html","options":{"xdomain":"*","allowfullscreen":false,"lazyload":false}},"evals":[],"jsHooks":[]}</script>
<p><img src="/codex_model_files/figure-html/Density%20plots%20for%20predictions%20for%20matches%20with%20simple%20decks-1.png" width="672" /><img src="/codex_model_files/figure-html/Density%20plots%20for%20predictions%20for%20matches%20with%20simple%20decks-2.png" width="672" /><img src="/codex_model_files/figure-html/Density%20plots%20for%20predictions%20for%20matches%20with%20simple%20decks-3.png" width="672" /></p>
<p>If the model predicted matches by saying the most likely winner would win, its performance on the above matches, which were used to fit it, would be 345 out of 403 (85.6%). Since it gives a probability of each player winning, we can use proper scoring rules instead (the closer to zero, the better):</p>
<table>
<thead>
<tr>
<th style="text-align:left;">
model
</th>
<th style="text-align:right;">
log score
</th>
<th style="text-align:right;">
Brier score
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
predict every match as 5-5
</td>
<td style="text-align:right;">
0.693
</td>
<td style="text-align:right;">
0.250
</td>
</tr>
<tr>
<td style="text-align:left;">
current model
</td>
<td style="text-align:right;">
0.404
</td>
<td style="text-align:right;">
0.123
</td>
</tr>
</tbody>
</table>
</div>
<div id="player-skill" class="section level1">
<h1>Player skill</h1>
<p>Player skills are given as their (additive) effect on their log-odds of winning a match. Skill is currently assumed to not change over time, so given skill levels for long-absent players are narrowly-distributed compared to how certain we’d really be about their current skill level. It’ll also favour players who were veterans before the earliest recorded match, because the period where they learned the ropes is not included in their match records.</p>
<p><img src="/codex_model_files/figure-html/plot%20vs%20models%20player%20skills-1.png" width="672" /></p>
<p><img src="/codex_model_files/figure-html/plot%20probability%20player%20is%20best-1.png" width="672" /></p>
<div id="htmlwidget-2" style="width:100%;height:100%;" class="widgetframe html-widget"></div>
<script type="application/json" data-for="htmlwidget-2">{"x":{"url":"/codex_model_files/figure-html//widgets/widget_player skill table.html","options":{"xdomain":"*","allowfullscreen":false,"lazyload":false}},"evals":[],"jsHooks":[]}</script>
</div>
<div id="opposed-component-effects" class="section level1">
<h1>Opposed component effects</h1>
<p>Decks are treated in opposing pairs: P1 starter versus P2 starter, P1 starter versus each P2 spec, and so on. Each match has 16 such pairs. Each pair’s effect is given as its additive effect on the log-odds of a player 1 victory. The component’s effects are added to given overall matchup between the decks, before accounting for player skill levels.</p>
<p>Note that these pair effects are <em>not</em> direct appraisals of how the components fare against each other. For each, the Green vs. Black effect doesn’t assess how those two decks decks match up against each other, it assesses how decks using those starter decks <em>tend</em> to match up against each other. Similarly, Blood vs. Future doesn’t, directly assess how those two specs compete at, say, Tech II, because I don’t record tech building choices. Instead, it shows how P1 decks including Blood tend to fare against P2 decks including Future. Note that this also ignores interactions between different pairs completely.</p>
<p>To examine the matchup between two particular decks, add their components in the relevant Deck components column. The overall matchup is then given below the table, as both the log-odds and the probability of a player 1 victory. Individual pair effects are given in the displayed table rows.</p>
<p>Currently I’ve not added the players in the same table to account for skill effects. In the meantime, since player skill tends to have a larger effect than the deck matchup, don’t compare the deck matchups to your own match outcomes too strictly, unless you can manually add the effects from the player table (remember to subtract the P2 effect, not add it).</p>
<div id="htmlwidget-3" style="width:100%;height:100%;" class="widgetframe html-widget"></div>
<script type="application/json" data-for="htmlwidget-3">{"x":{"url":"/codex_model_files/figure-html//widgets/widget_simple versus table.html","options":{"xdomain":"*","allowfullscreen":false,"lazyload":false}},"evals":[],"jsHooks":[]}</script>
</div>
<div id="monocolour-matchups" class="section level1">
<h1>Monocolour matchups</h1>
<p>Since we’re most interested in whether monocolour decks are reasonably balanced, here are matchup results for the monocolour decks. The three black vertical lines in each plot facet show the matchup quartiles.</p>
<p><img src="/codex_model_files/figure-html/make%20vs%20model%20monocolour%20matchup%20plots-1.png" width="672" /></p>
<div id="htmlwidget-4" style="width:100%;height:100%;" class="widgetframe html-widget"></div>
<script type="application/json" data-for="htmlwidget-4">{"x":{"url":"/codex_model_files/figure-html//widgets/widget_print vs model monocolour matchups in order.html","options":{"xdomain":"*","allowfullscreen":false,"lazyload":false}},"evals":[],"jsHooks":[]}</script>
</div>
<div id="model-variances" class="section level1">
<h1>Model variances</h1>
<p>Each type of component in the model has a different variance in the effect; inference for the variances is also done in the model simulation. The below plot shows the variances for each component type, scaled by how many such components go into a matchup, i.e. two player skill components, one starter vs. starter component, six starter vs. spec / spec vs. starter components, and nine spec vs. spec components.</p>
<p><img src="/codex_model_files/figure-html/plot%20versus%20model%20variances-1.png" width="672" /></p>
<p>On average, total player skill effects on match outcome are about 2.22 as variable as total deck effects. This is a rough measure of how important to a match the players are, compared to the decks.</p>
</div>
<div id="nash-equilibria" class="section level1">
<h1>Nash equilibria</h1>
<p>For a set of decks, we can take the matchup samples, and determine a Nash equilibrium for choosing which deck to use from that set. This can be done in two ways:</p>
<ul>
<li>Greedy: Find the Nash equilibrium of the mean matchups. This picks a strategy based on taking the model’s predicted matchups as correct. Using it to choose a deck is equivalent to always choosing the arm currently considered most likely to be the best in a multi-armed bandit problem. For the above plot of each player’s probability of being the best player, this would always state that the most-likely-best player is the best.</li>
<li>Calibrated: Find the Nash equilibria for each sample of matchups, and take the mean equilibrium. This takes proper account of the model’s uncertainty over the matchups. Using it to choose a deck is equivalent to Thompson sampling: for player skills, this would randomly choose a player to state as the best, weighted by the players’ probabilities of being the best. This approach is better calibrated.</li>
</ul>
<div id="monocolour" class="section level2">
<h2>Monocolour</h2>
<p>Greedy:</p>
<table>
<thead>
<tr>
<th style="text-align:left;">
Player
</th>
<th style="text-align:right;">
Win probability
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
P1
</td>
<td style="text-align:right;">
0.478
</td>
</tr>
<tr>
<td style="text-align:left;">
P2
</td>
<td style="text-align:right;">
0.522
</td>
</tr>
<tr>
<td style="text-align:left;">
Both
</td>
<td style="text-align:right;">
0.500
</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:left;">
Deck
</th>
<th style="text-align:right;">
P1
</th>
<th style="text-align:right;">
P2
</th>
<th style="text-align:right;">
Both
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
MonoBlack
</td>
<td style="text-align:right;">
0.324
</td>
<td style="text-align:right;">
0.817
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
MonoRed
</td>
<td style="text-align:right;">
0.676
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
MonoWhite
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
0.183
</td>
<td style="text-align:right;">
0
</td>
</tr>
</tbody>
</table>
<p>Calibrated:</p>
<table>
<thead>
<tr>
<th style="text-align:left;">
Player
</th>
<th style="text-align:right;">
Win probability
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
P1
</td>
<td style="text-align:right;">
0.514
</td>
</tr>
<tr>
<td style="text-align:left;">
P2
</td>
<td style="text-align:right;">
0.486
</td>
</tr>
<tr>
<td style="text-align:left;">
Both
</td>
<td style="text-align:right;">
0.500
</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:left;">
Deck
</th>
<th style="text-align:right;">
P1
</th>
<th style="text-align:right;">
P2
</th>
<th style="text-align:right;">
Both
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
MonoBlack
</td>
<td style="text-align:right;">
0.329
</td>
<td style="text-align:right;">
0.451
</td>
<td style="text-align:right;">
0.645
</td>
</tr>
<tr>
<td style="text-align:left;">
MonoRed
</td>
<td style="text-align:right;">
0.279
</td>
<td style="text-align:right;">
0.092
</td>
<td style="text-align:right;">
0.132
</td>
</tr>
<tr>
<td style="text-align:left;">
MonoWhite
</td>
<td style="text-align:right;">
0.157
</td>
<td style="text-align:right;">
0.122
</td>
<td style="text-align:right;">
0.076
</td>
</tr>
<tr>
<td style="text-align:left;">
MonoBlue
</td>
<td style="text-align:right;">
0.102
</td>
<td style="text-align:right;">
0.101
</td>
<td style="text-align:right;">
0.062
</td>
</tr>
<tr>
<td style="text-align:left;">
MonoPurple
</td>
<td style="text-align:right;">
0.061
</td>
<td style="text-align:right;">
0.159
</td>
<td style="text-align:right;">
0.055
</td>
</tr>
<tr>
<td style="text-align:left;">
MonoGreen
</td>
<td style="text-align:right;">
0.073
</td>
<td style="text-align:right;">
0.075
</td>
<td style="text-align:right;">
0.029
</td>
</tr>
</tbody>
</table>
<p>As would be expected, the chance of winning before determining play order is 50%. Black is dominant, as expected given that it’s known as a strong faction. The only exception is when known to be going first, where Red plays a significant role. However, this is less clear-cut in the calibrated results: even Blue, considered weak due to an especially lopsided matchup against Black, hasn’t been completely cut out.</p>
</div>
<div id="all-recorded-decks" class="section level2">
<h2>All recorded decks</h2>
<p>The current way I calculate Nash equilbria makes computing them for all 3084 possible standard multicolour decks infeasible. I’m working on fixing this. In the meantime, here are the Nash equilibria for all 105 such decks used in a recorded tournament match.</p>
<p>Nash equilibria are given for three types of player: <code>P1</code> when known to be going first, <code>P2</code> when known to be going second, and <code>Both</code> for the more common case where the deck is chosen before a coin flip to determine who goes first.</p>
<div id="win-probability" class="section level3">
<h3>Win probability</h3>
<p>Greedy:</p>
<table>
<thead>
<tr>
<th style="text-align:left;">
Player
</th>
<th style="text-align:right;">
Win probability
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
P1
</td>
<td style="text-align:right;">
0.546
</td>
</tr>
<tr>
<td style="text-align:left;">
P2
</td>
<td style="text-align:right;">
0.454
</td>
</tr>
<tr>
<td style="text-align:left;">
Both
</td>
<td style="text-align:right;">
0.500
</td>
</tr>
</tbody>
</table>
<p>Calibrated:</p>
<table>
<thead>
<tr>
<th style="text-align:left;">
Player
</th>
<th style="text-align:right;">
Win probability
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
P1
</td>
<td style="text-align:right;">
0.539
</td>
</tr>
<tr>
<td style="text-align:left;">
P2
</td>
<td style="text-align:right;">
0.461
</td>
</tr>
<tr>
<td style="text-align:left;">
Both
</td>
<td style="text-align:right;">
0.500
</td>
</tr>
</tbody>
</table>
<p>The first player seems to be more advantaged than in the monocolour game, though not by much.</p>
</div>
<div id="non-zero-deck-weights" class="section level3">
<h3>Non-zero deck weights</h3>
<p>Greedy:</p>
<div id="htmlwidget-5" style="width:100%;height:100%;" class="widgetframe html-widget"></div>
<script type="application/json" data-for="htmlwidget-5">{"x":{"url":"/codex_model_files/figure-html//widgets/widget_greedy possibly normal Nash datatable.html","options":{"xdomain":"*","allowfullscreen":false,"lazyload":false}},"evals":[],"jsHooks":[]}</script>
<p>Calibrated:</p>
<div id="htmlwidget-6" style="width:100%;height:100%;" class="widgetframe html-widget"></div>
<script type="application/json" data-for="htmlwidget-6">{"x":{"url":"/codex_model_files/figure-html//widgets/widget_calibrated possibly normal Nash datatable.html","options":{"xdomain":"*","allowfullscreen":false,"lazyload":false}},"evals":[],"jsHooks":[]}</script>
<p>Notably, no decks have been eliminated in the calibrated version, so there is still a lot of uncertainty.</p>
</div>
</div>
</div>
