---
title: "CAWS19 predictions and results"
author: "Mark Webster"
date: "2020-02-18"
output:
  html_document:
    number_sections: false
    code_folding: none
---

```{r, "setup", include=FALSE}
library(tidyverse)
library(magrittr)
library(data.table)
library(codex)
library(DT)
library(widgetframe)
library(lpSolve)
library(kableExtra)
knitr::opts_chunk$set(echo = FALSE)
```

```{r, "read model results"}
model_names <- "Versus model, forum data"
results_file_subnames <- "vs_split"
results_file_names <- "codex_files/tidy_vs_split.rds"
results <- stats::setNames(Map(readRDS, results_file_names), model_names)
```

```{r, "read model samples"}
sims <- stats::setNames(Map("[[", results, "tidy_results"), model_names)
attach(stats::setNames(sims, paste0("sim_", results_file_subnames)))
```

```{r, "extract versus model sims"}
vs_results <- results[str_detect(names(results), "Versus")]
vs_sims <- sims[str_detect(names(sims), "Versus")]
```

Everything on this page uses the same 4000 samples as on [the main model page](../codex_model), so the same caveats apply regarding accuracy of win probabilities, and player skills probably being biased against more recent players.

# CAWS19 predictions

Tournament entrants:

```{r, "CAWS19 matchups"}
caws_players <- c("FrozenStorm", "charnel_mouse", 
                  "CarpeGuitarrem", 
                  "zhavier", "Nopethebard", "Akiata", 
                  "Bomber678", "bolyarich", "dwarddd", "EricF", 
                  "codexnewb")
caws_decks <- standardise_deck_name(c("[Future]/Peace/Necromancy", "[Balance]/Blood/Strength", 
                                      "[Necromancy]/Blood/Present", 
                                      "[Balance]/Growth/Finesse", "MonoRed", "[Past]/Peace/Anarchy", 
                                      "MonoRed", "Nightmare", "[Past/Present]/Peace", "[Feral]/Law/Fire", 
                                      "Miracle Grow"), 
                                    codex::starters, codex::nicknames)
caws_entries <- data.table(player = caws_players, deck = caws_decks, stringsAsFactors = TRUE)
kable(caws_entries)
caws_valid <- !is.na(caws_decks)
```

## Matchup predictions

Matchups for decks only, ignoring player skill levels:

```{r, "matchup plot with wrap function"}
plot_samples_wrap <- function(matchup_samples) {
  plot_matchup_samples(matchup_samples[, .(P1 = `levels<-`(P1, stringr::str_replace_all(levels(P1), "/", " ")),
                                                                               P2 = `levels<-`(P2, stringr::str_replace_all(levels(P2), "/", " ")),
                                                                               prob_matchup, prob_mean)], 2) +
  facet_grid(P1~P2, labeller = labeller(P1 = label_wrap_gen(10), P2 = label_wrap_gen(15)))
}
```

```{r, "CAWS19 matchup samples deck plot", fig.width=10.5, fig.height=7.5, warning=FALSE}
plot_samples_wrap(get_matchups(vs_results[[1]], caws_decks[caws_valid]))
```

```{r, "CAWS19 mean deck matchups"}
caws_deck_matchup_array <- get_matchup_array(vs_results[[1]], caws_decks[caws_valid])
caws_deck_matchups <- apply(caws_deck_matchup_array, 2:3, mean)
frameWidget(DT_mean_matchup(caws_deck_matchups, "D"),
            height = "100%")
```

Matchups for players, accounting for deck strengths:

```{r, "CAWS19 matchup samples plot", fig.width=10.5, fig.height=7.5, warning=FALSE}
plot_matchup_samples(get_matchups(vs_results[[1]], caws_decks[caws_valid], caws_players[caws_valid]), 2)
```

```{r, "CAWS19 mean matchups"}
caws_matchup_array <- get_matchup_array(vs_results[[1]], caws_decks[caws_valid], caws_players[caws_valid])
caws_matchups <- apply(caws_matchup_array, 2:3, mean)
frameWidget(DT_mean_matchup(caws_matchups, "P"),
            height = "100%")
```

## Nash equilibria

We can find the Nash equilibria for the case where we could pick one of the decks, or one of the player/deck pairs, in a match. This should be taken with a large pinch of salt when using it to guess who would win the tournament, but it's a simple heurustic for likely contenders.

Nash equilibria are calculated by finding the equilibria for each of the 4000 model samples, then taking the mean. This accounts for the model's posterior uncertainty, so will give more widely-distributed probability distributions than forum-goers might expect.

```{r, "CAWS19 mean Nash data"}
caws_deck_nash_samples <- get_nash_equilibria(caws_deck_matchup_array)
caws_deck_mean_nash <- as.data.table(apply(caws_deck_nash_samples, 1:2, mean), 
                                     keep.rownames = "Player")[, c(.(Player = factor(Player, 
                                                                                     c("P1", "P2", "Both"))), 
                                                                   .SD), 
                                                               .SDcols = dimnames(caws_deck_nash_samples)[[2]]]
caws_nash_samples <- get_nash_equilibria(caws_matchup_array)
caws_mean_nash <- as.data.table(apply(caws_nash_samples, 1:2, mean), 
                                keep.rownames = "Player")[, c(.(Player = factor(Player, 
                                                                                c("P1", "P2", "Both"))), 
                                                              .SD), 
                                                          .SDcols = dimnames(caws_nash_samples)[[2]]]
```

Nash for decks only, i.e. decks likely to be dominant if players were of equal skill:

```{r, "deck Nash"}
kable(print_nash(caws_deck_mean_nash), digits = 3)
kable(reformat_used_nash(caws_deck_mean_nash), digits = 3)
```

Nash for player/deck pairs:

```{r, "player Nash"}
kable(print_nash(caws_mean_nash), digits = 3)
kable(reformat_used_nash(caws_mean_nash), digits = 3)
```

# CAWS19 results

While we're waiting for CAWS19 to complete, at which point I'll add it to the training data, we can look at how the model's predictions are doing so far. Here's the data for all completed matches:

```{r, "CAWS19 matches"}
CAWS19_matches <- fread("codex_files/CAWS19.csv", colClasses = list(Date = c("start", "end")))
kable(CAWS19_matches[, c("round", "player1", "player2", "deck1", "deck2", "victor")])
```

And here's the comparison with predicted outcomes:

```{r, "CAWS19 counts"}
caws_matches_result_tallies <- CAWS19_matches[, .(P1 = as.factor(player1),
                                                  P2 = as.factor(player2),
                                                  `P1 win` = victor == player1)
                                              ]
caws_matches_counts <- caws_matches_result_tallies[, .(`P1 wins` = paste(sum(`P1 win`), .N, sep = "/")),
                                                   by = c("P1", "P2")]
```

```{r, "CAWS19 prediction evaluation"}
caws_matchups_table <- as.data.table(caws_matchups, keep.rownames = "P1")[, c(list(P1 = factor(P1, unique(P1))), .SD),
                                                                                      .SDcols = setdiff(colnames(caws_matchups), "P1")] %>% 
  melt(id.vars = "P1", variable.name = "P2", value.name = "matchup")
caws_lognormal_eval <- caws_matchups_table[caws_matches_counts, on = c("P1", "P2")
                                                ][order(P1, P2)]
kable(caws_lognormal_eval[order(-matchup, -`P1 wins`, P1, P2)], digits = 3)
```

How does the predicted match fairness change as the rounds progress?

```{r, "CAWS19 fairness progression"}
caws_fairness <- CAWS19_matches[, .(round, round_match_number,
                                    fairness = 1 - 2*abs(diag(caws_matchups[player1, player2]) - 1/2))]
ggplot(caws_fairness, aes(x = round, y = fairness)) +
  geom_point() +
  # geom_line(data = caws_fairness[, .(fairness = mean(fairness)), by = "round"]) +
  ggtitle("Predicted match fairness by tournament round", "Completed matches only")
```

Average Brier score:

```{r}
score <- caws_matchups_table[caws_matches_result_tallies, on = c("P1", "P2")
                             ][, mean((`P1 win` - matchup)^2)]
kable(data.table(model = c("predict all matches as 5-5", "current model"),
                 `Brier score` = c(1/4, score)),
      digits = 3)
```

Compare to the Brier score for the training data on [the main model page](../codex_model).
